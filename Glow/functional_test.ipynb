{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn.parameter import Parameter\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ActNorm(nn.Module):\n",
    "    def __init__(self, n_channel):\n",
    "        super().__init__()\n",
    "        self.n_channel = n_channel\n",
    "\n",
    "        self.scale = Parameter(torch.Tensor(1,n_channel,1,1))\n",
    "        self.bias = Parameter(torch.Tensor(1,n_channel,1,1))\n",
    "        self.initialize = False\n",
    "    def forward(self, x):\n",
    "        #x: bxcxhxw Tensor\n",
    "        #return: output(bxcxhxw Tensor), log_det(b Tensor)\n",
    "        b, c, h, w = x.shape\n",
    "        assert x.shape[1] == self.n_channel\n",
    "        output = torch.clone(x)\n",
    "        # Initialize into zero-mean, unit variance of mini-batch\n",
    "        if not self.initialize: \n",
    "            data = output.transpose(0,1).reshape(self.n_channel,-1)\n",
    "            std, mean = torch.std_mean(data, dim = -1)\n",
    "            std, mean = std.view(1, self.n_channel, 1, 1), mean.view(1, self.n_channel, 1, 1)\n",
    "            self.scale.data.copy_(1/(std+1e-9))\n",
    "            self.bias.data.copy_(-mean)\n",
    "            self.initialize = True\n",
    "        output += self.bias\n",
    "        output *= self.scale\n",
    "\n",
    "        log_det = h * w * self.scale.abs().log().sum()\n",
    "        log_det = log_det.repeat(b)\n",
    "        return output, log_det\n",
    "    def reverse(self, z): \n",
    "        #왠지 모르겟지만 Clone을 쓰지 않을 경우, input으로 들어가는 Tensor 객체가 바뀜\n",
    "        output = torch.clone(z)\n",
    "        output /= self.scale\n",
    "        output -= self.bias\n",
    "        return output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "log_det, -18.91\n"
     ]
    }
   ],
   "source": [
    "b, c, h, w = 4, 10, 32, 32\n",
    "x = torch.randn(b, c, h, w)\n",
    "model = ActNorm(c)\n",
    "z, log_det = model(x)\n",
    "x_reverse = model.reverse(z)\n",
    "#check initialize into 0 mean, Unit Variance\n",
    "z_std, z_mean = torch.std_mean(z.transpose(0,1).reshape(c, -1), dim = -1)\n",
    "assert torch.allclose(z_mean, torch.zeros_like(z_mean), atol = 1e-7)\n",
    "assert torch.allclose(z_std, torch.ones_like(z_std), atol = 1e-7)\n",
    "#check log_det\n",
    "print(f\"log_det, {log_det[0].item():.2f}\")\n",
    "assert log_det.shape == (b, )\n",
    "#check invertible\n",
    "assert torch.allclose(x_reverse, x, atol = 1e-7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImageAffineCouplingLayer(nn.Module):\n",
    "    def __init__(self, n_channel):\n",
    "        super().__init__()\n",
    "        self.n_channel = n_channel\n",
    "        #split along channel\n",
    "        self.n_split = n_channel // 2\n",
    "\n",
    "        self.nn = nn.Sequential(\n",
    "            nn.Conv2d(self.n_split, 512, 3, padding =1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(512, 512, 1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(512, 2*(self.n_channel - self.n_split), 3, padding = 1)\n",
    "        )\n",
    "        #init last weight into zero\n",
    "        nn.init.constant_(self.nn[-1].weight, 0)\n",
    "        nn.init.constant_(self.nn[-1].bias, 0)\n",
    "    def forward(self, x):\n",
    "        # x: bxcxhxw\n",
    "        b,c,h,w = x.shape\n",
    "        assert self.n_channel == c\n",
    "        x_a, x_b = x[:,:self.n_split], x[:,self.n_split:]\n",
    "        nn_result = self.nn(x_a) #bx2(D-d) x h x w\n",
    "        #log_s, t: bx(D-d)xhxw\n",
    "        log_s, t = nn_result[:,0::2,:,:], nn_result[:,1::2,:,:]\n",
    "        # s = torch.exp(log_s) #log_s는 initially 0\n",
    "        s = torch.sigmoid(log_s + 2) #torch.exp대문에 잘 안되는 듯??\n",
    "        y_a, y_b = x_a, s*x_b + t\n",
    "        y = torch.cat((y_a, y_b), dim = 1)\n",
    "        log_det = s.view(b, -1).abs().log().sum(dim = 1)\n",
    "\n",
    "        return y, log_det\n",
    "    def reverse(self, z):\n",
    "        # z: bxcxhxw\n",
    "        z_a, z_b = z[:,:self.n_split], z[:,self.n_split:]\n",
    "        nn_result = self.nn(z_a) #bx2(D-d) x h x w\n",
    "        log_s, t = nn_result[:,0::2,:,:], nn_result[:,1::2,:,:]\n",
    "        # s = torch.exp(log_s)\n",
    "        s = torch.sigmoid(log_s + 2)\n",
    "        x_a, x_b = z_a, (z_b-t)/s\n",
    "        x = torch.cat((x_a, x_b), dim = 1)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "-649.8717651367188\n"
     ]
    }
   ],
   "source": [
    "b, c, h, w = 4, 10, 32, 32\n",
    "split = 3\n",
    "x = torch.randn(b,c,h,w)\n",
    "model = ImageAffineCouplingLayer(n_channel = c)\n",
    "z, log_det = model(x)\n",
    "x2 = model.reverse(z)\n",
    "#check z == x at first\n",
    "# assert torch.allclose(x, z, atol = 1e-7)\n",
    "#check invertible\n",
    "assert torch.allclose(x, x2, atol = 1e-7)\n",
    "#check log_det\n",
    "assert log_det.shape == (b,)\n",
    "print(log_det.mean().item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Invertible1to1Conv(nn.Module):\n",
    "    def __init__(self, n_channel):\n",
    "        super().__init__()\n",
    "        self.n_channel = n_channel\n",
    "        #LDU decomposition안해도 괜찮은 성능인 듯 하여 안씀\n",
    "        self.matrix = Parameter(torch.Tensor(self.n_channel, self.n_channel))\n",
    "        \n",
    "        #initialize with random permutation matrix\n",
    "        init_matrix = torch.eye(self.n_channel)\n",
    "        randperm = torch.randperm(self.n_channel)\n",
    "        init_matrix = init_matrix[:, randperm]\n",
    "        self.matrix.data.copy_(init_matrix)\n",
    "    def forward(self, x):\n",
    "        #x: bxcxhxw\n",
    "        b,c,h,w = x.shape \n",
    "        output = x.transpose(1, -1) # bxhxwxc\n",
    "        output = torch.matmul(output, self.matrix) #bxhxwxc\n",
    "        log_det = h*w*self.matrix.det().abs().log().repeat(b)\n",
    "        return output.transpose(1, -1), log_det\n",
    "    def reverse(self, z):\n",
    "        output = z.transpose(1, -1)\n",
    "        output = torch.matmul(output, self.matrix.inverse())\n",
    "        return output.transpose(1, -1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "b, c, h, w = 4, 1000, 32, 32\n",
    "x = torch.randn(b,c,h,w)\n",
    "model = Invertible1to1Conv(n_channel = c)\n",
    "z, log_det = model(x)\n",
    "x2 = model.reverse(z)\n",
    "#check invertible\n",
    "assert torch.allclose(x, x2, atol = 1e-7)\n",
    "#check model matrix, permutation으로 det = 0\n",
    "assert torch.allclose(log_det , torch.zeros(b), atol = 1e-7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GlowBlock(nn.Module):\n",
    "    def __init__(self, n_channel):\n",
    "        super().__init__()\n",
    "        self.step = nn.ModuleList([\n",
    "            ActNorm(n_channel = n_channel),\n",
    "            Invertible1to1Conv(n_channel = n_channel),\n",
    "            ImageAffineCouplingLayer(n_channel = n_channel),\n",
    "        ])\n",
    "    def forward(self, x):\n",
    "        b,c,h,w = x.shape\n",
    "        output, log_det = x, 0 \n",
    "        for layer in self.step:\n",
    "            output, log_det_ = layer(output)\n",
    "            log_det += log_det_\n",
    "        return output, log_det\n",
    "    def reverse(self, z):\n",
    "        output = z\n",
    "        for layer in self.step[::-1]:\n",
    "            output = layer.reverse(output)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "b, c, h, w = 4, 10, 32, 32\n",
    "x = torch.randn(b,c,h,w)\n",
    "model = GlowBlock(n_channel= c)\n",
    "z, log_det = model(x)\n",
    "x2 = model.reverse(z)\n",
    "assert torch.allclose(x, x2, atol = 1e-7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GlowLevel(nn.Module):\n",
    "    def __init__(self, n_channel, n_flow, split = True):\n",
    "        super().__init__()\n",
    "        self.n_channel, self.n_flow, self.split = n_channel, n_flow, split\n",
    "        self.step = nn.ModuleList([GlowBlock(n_channel = n_channel* 4) for _ in range(n_flow)])\n",
    "    def forward(self, x):\n",
    "        b, c, h, w = x.shape\n",
    "        c_out, h_out, w_out = c*4, h//2, w//2\n",
    "        output = x.view(b,c,h_out,2,w_out,2).permute(0,1,3,5,2,4).reshape(b, c_out, h_out, w_out)\n",
    "        log_det = 0\n",
    "        for layer in self.step:\n",
    "            output, log_det_ = layer(output)\n",
    "            log_det += log_det_\n",
    "        if self.split:\n",
    "            z_new, output = output.chunk(2 , dim = 1)\n",
    "            return (z_new, output), log_det\n",
    "        else:\n",
    "            return output, log_det\n",
    "    def reverse(self, z):\n",
    "        output = None\n",
    "        if self.split:\n",
    "            z1, z2 = z\n",
    "            output = torch.cat([z1,z2], dim = 1)\n",
    "        else:\n",
    "            output = z\n",
    "        b, c, h, w = output.shape\n",
    "        for layer in self.step[::-1]:\n",
    "            output = layer.reverse(output)\n",
    "        output = output.view(b, c//4, 2, 2, h, w).permute(0, 1, 4, 2, 5, 3)\n",
    "        output = output.reshape(b , c//4, h*2, w*2)\n",
    "        return output\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "b, c, h, w = 4, 10, 32, 32\n",
    "x = torch.randn(b, c,h,w)\n",
    "model = GlowLevel(n_channel= c, n_flow = 10)\n",
    "z, log_det = model(x)\n",
    "z1, z2 = z\n",
    "x2 = model.reverse(z)\n",
    "assert z1.shape == z2.shape\n",
    "assert torch.allclose(x, x2, atol = 1e-7)\n",
    "model = GlowLevel(n_channel= c, n_flow = 10, split = False)\n",
    "z, log_det = model(x)\n",
    "x2 = model.reverse(z)\n",
    "assert z.shape == (b, 4*c, h//2, w//2)\n",
    "assert torch.allclose(x, x2, atol = 1e-7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Glow(nn.Module):\n",
    "    def __init__(self, n_channel, n_flow, n_level):\n",
    "        super().__init__()\n",
    "        self.n_level, self.n_flow, self.n_channel = n_level, n_flow, n_channel\n",
    "        self.blocks = nn.ModuleList([GlowLevel(n_channel = self.n_channel *(2**idx), \n",
    "                                               split = idx!= self.n_level-1, n_flow = n_flow) for idx in range(self.n_level)])\n",
    "    def forward(self, x):\n",
    "        b,c,h,w = x.shape\n",
    "        hidden, z_arr, log_det = x, [], 0\n",
    "        for layer in self.blocks[:-1]:\n",
    "            (z, hidden), log_det_= layer(hidden)\n",
    "            z_arr.append(z)\n",
    "            log_det += log_det_\n",
    "        z, log_det_ = self.blocks[-1](hidden)\n",
    "        log_det += log_det_\n",
    "        z_arr.append(z)\n",
    "        return z_arr, log_det\n",
    "    def reverse(self, z):\n",
    "        hidden = self.blocks[-1].reverse(z[-1])\n",
    "        for idx in range(2, self.n_level+1):\n",
    "            hidden = self.blocks[-idx].reverse((z[-idx], hidden))\n",
    "        return hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_latent(n_level = 3, image_shape= (10, 3, 32, 32), device = torch.device(\"cpu\")):\n",
    "    b, c, h, w = image_shape\n",
    "    z_arr =[]\n",
    "    for idx in range(n_level):\n",
    "        multiple = 2**(idx+1)\n",
    "        channel = c*multiple\n",
    "        if n_level -1 == idx:\n",
    "            channel *= 2\n",
    "        z_arr.append(torch.randn(b, channel, h//multiple, w//multiple, device = device))\n",
    "    return z_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_model_size(model):\n",
    "    n_params = np.sum([p.numel() for p in model.parameters()])\n",
    "    print(f\"{n_params* 4 /10**6:2f}MB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "175.793664MB\n"
     ]
    }
   ],
   "source": [
    "b, c, h, w = 4, 3, 32, 32\n",
    "x = torch.randn(b,c,h,w)\n",
    "model = Glow(n_channel= c, n_flow= 32, n_level = 3)\n",
    "z, log_det = model(x)\n",
    "x2 = model.reverse(z)\n",
    "assert torch.allclose(x, x2, atol = 1e-7)\n",
    "#check make_latent make same shape\n",
    "new_z = make_latent(3, (b,c,h,w))\n",
    "assert len(z) == len(new_z)\n",
    "for idx in range(len(z)):\n",
    "    assert z[idx].shape == new_z[idx].shape, f\"{idx} error\"\n",
    "n_params = np.sum([p.numel() for p in model.parameters()])\n",
    "print(f\"{n_params* 4 /10**6:2f}MB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\")\n",
    "# model.to(device), 1.3GB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import time\n",
    "def time_check(start):\n",
    "    total_time = round(time() - start)\n",
    "    min, seconds = divmod(total_time, 60)\n",
    "    return \"{:02}:{:02}\".format(int(min),int(seconds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Files already downloaded and verified\n",
      "[0,31]: time: 00:24 train_loss: 14851.8680\n",
      "[1,62]: time: 00:24 train_loss: 13204.4499\n",
      "[2,93]: time: 00:24 train_loss: 12019.0395\n",
      "[3,124]: time: 00:24 train_loss: 11498.7102\n",
      "[4,155]: time: 00:24 train_loss: 10896.4355\n",
      "[5,186]: time: 00:24 train_loss: 10492.8645\n",
      "[6,217]: time: 00:24 train_loss: 10174.2690\n",
      "[7,248]: time: 00:24 train_loss: 10091.5697\n",
      "[8,279]: time: 00:24 train_loss: 10029.0329\n",
      "[9,310]: time: 00:24 train_loss: 9939.2910\n",
      "[10,341]: time: 00:24 train_loss: 9747.4722\n",
      "[11,372]: time: 00:24 train_loss: 9718.5530\n",
      "[12,403]: time: 00:24 train_loss: 9764.2184\n",
      "[13,434]: time: 00:24 train_loss: 9683.0403\n",
      "[14,465]: time: 00:24 train_loss: 9680.5428\n",
      "[15,496]: time: 00:24 train_loss: 9513.7864\n",
      "[16,527]: time: 00:24 train_loss: 9532.6306\n",
      "[17,558]: time: 00:24 train_loss: 9464.0624\n",
      "[18,589]: time: 00:24 train_loss: 9506.5529\n",
      "[19,620]: time: 00:24 train_loss: 9380.0016\n",
      "[20,651]: time: 00:24 train_loss: 9379.7689\n",
      "[21,682]: time: 00:24 train_loss: 9693.8839\n",
      "[22,713]: time: 00:24 train_loss: 9510.7516\n",
      "[23,744]: time: 00:24 train_loss: 9298.8729\n",
      "[24,775]: time: 00:24 train_loss: 9330.8300\n",
      "[25,806]: time: 00:24 train_loss: 9207.0695\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-5517c2cedeab>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     36\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_prior\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mlog_det\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mn_pixel\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m256\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m         \u001b[0mn_iter\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    219\u001b[0m                 \u001b[0mretain_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    220\u001b[0m                 create_graph=create_graph)\n\u001b[0;32m--> 221\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    222\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m    128\u001b[0m         \u001b[0mretain_graph\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 130\u001b[0;31m     Variable._execution_engine.run_backward(\n\u001b[0m\u001b[1;32m    131\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    132\u001b[0m         allow_unreachable=True)  # allow_unreachable flag\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from torch.optim import Adam\n",
    "from torchvision.datasets import CIFAR10\n",
    "import torchvision.transforms as T\n",
    "from torchvision.utils import save_image\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "train_data = CIFAR10(\"./data\", train= True, download = True, transform = T.Compose([T.ToTensor()]))\n",
    "train_loader = DataLoader(train_data, batch_size= 64, shuffle= True, num_workers= 4)\n",
    "#Temperature\n",
    "\n",
    "device = torch.device(\"cuda:0\")\n",
    "\n",
    "model = Glow(n_channel= 3, n_flow = 32, n_level= 3)\n",
    "model.to(device)\n",
    "optimizer = Adam(model.parameters(), lr = 5e-5)\n",
    "\n",
    "n_pixel = 32*32*3\n",
    "n_bits = 5\n",
    "\n",
    "train_loss_arr = []\n",
    "n_iter = 0\n",
    "for ep in range(100):\n",
    "    model.train()\n",
    "    ep_train_loss_arr = []\n",
    "    start = time()\n",
    "    for idx, (img, label) in enumerate(train_loader):\n",
    "        # if idx> 30:\n",
    "        #     break\n",
    "        img = img.to(device)\n",
    "        batch_size = img.shape[0]\n",
    "        optimizer.zero_grad()\n",
    "        output, log_det = model(img)\n",
    "        output = [latent.reshape(batch_size, -1) for latent in output]\n",
    "        output = torch.cat(output, dim = 1)\n",
    "        loss_prior = ((output ** 2+ np.log(2 * np.pi))/2).sum(dim = 1)\n",
    "        loss = loss_prior - log_det + n_pixel *np.log(256)\n",
    "        loss = loss.mean()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        n_iter += 1\n",
    "        ep_train_loss_arr.append(loss.item())\n",
    "    train_loss_arr += ep_train_loss_arr\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        z = make_latent(n_level = 3, image_shape = (10, 3, 32, 32), device = device)\n",
    "        generated = model.reverse(z)\n",
    "        save_image(generated, f\"Samples/{ep}_images.jpg\",nrow = 10)\n",
    "    print(f\"[{ep},{n_iter}]: time: {time_check(start)} train_loss: {np.mean(ep_train_loss_arr):.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}