{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "root = \"./dataset/mnist\"\n",
    "trn_dataset = datasets.MNIST(root,\n",
    "                             download=True,\n",
    "                             train=True,\n",
    "                             transform=transforms.Compose([\n",
    "                                 transforms.Pad(2),\n",
    "                                 transforms.ToTensor(), # image to Tensor\n",
    "                                 transforms.Normalize(0,1)\n",
    "                             ])) \n",
    "\n",
    "val_dataset = datasets.MNIST(root, \n",
    "                             download=True,\n",
    "                             train=False,\n",
    "                             transform= transforms.Compose([\n",
    "                               transforms.Pad(2),\n",
    "                               transforms.ToTensor(),\n",
    "                               transforms.Normalize(0,1)\n",
    "                           ]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "batch_size = 256\n",
    "trn_loader = DataLoader(trn_dataset,batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset,batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1/20 | trn loss: 0.6977 | val loss: 0.2654 | trn_acc: 0.790 | val_acc: 0.919\n",
      "epoch: 2/20 | trn loss: 0.2030 | val loss: 0.1417 | trn_acc: 0.937 | val_acc: 0.955\n",
      "epoch: 3/20 | trn loss: 0.1321 | val loss: 0.0937 | trn_acc: 0.960 | val_acc: 0.971\n",
      "epoch: 4/20 | trn loss: 0.0981 | val loss: 0.0801 | trn_acc: 0.970 | val_acc: 0.976\n",
      "epoch: 5/20 | trn loss: 0.0833 | val loss: 0.0762 | trn_acc: 0.974 | val_acc: 0.976\n",
      "epoch: 6/20 | trn loss: 0.0713 | val loss: 0.0596 | trn_acc: 0.978 | val_acc: 0.981\n",
      "epoch: 7/20 | trn loss: 0.0606 | val loss: 0.0630 | trn_acc: 0.981 | val_acc: 0.980\n",
      "epoch: 8/20 | trn loss: 0.0548 | val loss: 0.0516 | trn_acc: 0.983 | val_acc: 0.984\n",
      "epoch: 9/20 | trn loss: 0.0500 | val loss: 0.0593 | trn_acc: 0.985 | val_acc: 0.981\n",
      "epoch: 10/20 | trn loss: 0.0449 | val loss: 0.0449 | trn_acc: 0.986 | val_acc: 0.985\n",
      "epoch: 11/20 | trn loss: 0.0401 | val loss: 0.0415 | trn_acc: 0.987 | val_acc: 0.987\n",
      "epoch: 12/20 | trn loss: 0.0399 | val loss: 0.0441 | trn_acc: 0.988 | val_acc: 0.986\n",
      "epoch: 13/20 | trn loss: 0.0348 | val loss: 0.0401 | trn_acc: 0.989 | val_acc: 0.987\n",
      "epoch: 14/20 | trn loss: 0.0315 | val loss: 0.0357 | trn_acc: 0.990 | val_acc: 0.988\n",
      "epoch: 15/20 | trn loss: 0.0284 | val loss: 0.0408 | trn_acc: 0.991 | val_acc: 0.988\n",
      "epoch: 16/20 | trn loss: 0.0276 | val loss: 0.0449 | trn_acc: 0.991 | val_acc: 0.986\n",
      "epoch: 17/20 | trn loss: 0.0248 | val loss: 0.0479 | trn_acc: 0.992 | val_acc: 0.986\n",
      "epoch: 18/20 | trn loss: 0.0237 | val loss: 0.0350 | trn_acc: 0.992 | val_acc: 0.989\n",
      "epoch: 19/20 | trn loss: 0.0205 | val loss: 0.0340 | trn_acc: 0.993 | val_acc: 0.988\n",
      "epoch: 20/20 | trn loss: 0.0210 | val loss: 0.0337 | trn_acc: 0.993 | val_acc: 0.990\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from torch.nn import CrossEntropyLoss\n",
    "from torch.optim import Adam\n",
    "from torch import save\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from NN.LeNet import LeNet\n",
    "\n",
    "learning_rate = 1e-3\n",
    "num_epoch = 20\n",
    "net =LeNet().cuda()\n",
    "\n",
    "criterion = CrossEntropyLoss()\n",
    "optimizer =Adam(net.parameters(), lr=learning_rate)\n",
    "\n",
    "summary = SummaryWriter(log_dir=\"runs/LeNet01\")\n",
    "\n",
    "\n",
    "trn_loss_list = []\n",
    "val_loss_list = []\n",
    "trn_size = len(trn_dataset)\n",
    "val_size = len(val_dataset)\n",
    "best_val_loss = float('inf')\n",
    "for epoch in range(num_epoch):\n",
    "    trn_loss = 0\n",
    "    trn_acc =0\n",
    "    net.train()\n",
    "    for _, (x,label) in enumerate(trn_loader):\n",
    "        x, label = x.cuda(), label.cuda()\n",
    "        optimizer.zero_grad()\n",
    "        pred = net(x)\n",
    "        loss = criterion(pred, label)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        trn_loss += loss.item()\n",
    "        pred,label = pred.cpu().detach().numpy(),label.cpu().detach().numpy()\n",
    "        trn_acc += np.sum(np.argmax(pred,axis=1)==label)\n",
    "        # del(memory saved)\n",
    "        del loss,pred\n",
    "        \n",
    "    trn_loss/=len(trn_loader)\n",
    "    trn_acc/=trn_size\n",
    "    \n",
    "    val_loss= 0\n",
    "    val_acc=0\n",
    "    net.eval()\n",
    "    for _, (x,label) in enumerate(val_loader):\n",
    "        x, label = x.cuda(), label.cuda()\n",
    "        \n",
    "        pred = net(x)\n",
    "        loss = criterion(pred, label)\n",
    "        \n",
    "        val_loss += loss.item()\n",
    "        pred,label = pred.cpu().detach().numpy(),label.cpu().detach().numpy()\n",
    "        val_acc += np.sum(np.argmax(pred,axis=1)==label)\n",
    "        del loss,pred\n",
    "    val_loss/=len(val_loader)\n",
    "    val_acc/=val_size\n",
    "    print(\"epoch: {}/{} | trn loss: {:.4f} | val loss: {:.4f} | trn_acc: {:.3f} | val_acc: {:.3f}\".format(\n",
    "                epoch+1, num_epoch, trn_loss, val_loss, trn_acc, val_acc))\n",
    "    if val_loss<best_val_loss:\n",
    "        save(net.state_dict(),'./Model/LeNet.pth')\n",
    "    summary.add_scalars('loss',{'valid':val_loss, 'train':trn_loss},epoch)    \n",
    "    summary.add_scalars('acc',{'valid':val_acc, 'train':trn_acc},epoch)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pred:7,true:7\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from torch import load\n",
    "net = LeNet()\n",
    "net.load_state_dict(load('Model/LeNet.pth'))\n",
    "dataiter= iter(val_loader)\n",
    "image, label = dataiter.next()\n",
    "image, label  = image[0],label[0]\n",
    "plt.imshow(image.reshape(32,32))\n",
    "image = image.reshape(1,1,32,32)\n",
    "net.eval()\n",
    "print(f\"pred:{label.item()},true:{np.argmax(net(image).cpu().detach().numpy())}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%load_ext tensorboard\n",
    "#%tensorboard --logdir=/runs"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
